<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenRouter Multi-Model Chat</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a1a;
            color: #e0e0e0;
            height: 100vh;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .tabs {
            display: flex;
            background: #2a2a2a;
            border-bottom: 1px solid #3a3a3a;
            padding: 0 12px;
        }

        .tab {
            padding: 12px 20px;
            cursor: pointer;
            border: none;
            background: none;
            color: #888;
            font-size: 14px;
            border-bottom: 2px solid transparent;
            transition: all 0.2s;
        }

        .tab:hover {
            color: #e0e0e0;
        }

        .tab.active {
            color: #e0e0e0;
            border-bottom-color: #4a9eff;
        }

        .tab-content {
            display: none;
            flex: 1;
            overflow: hidden;
            flex-direction: column;
        }

        .tab-content.active {
            display: flex;
        }

        #chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
        }

        .message {
            margin-bottom: 20px;
            max-width: 85%;
        }

        .message.user {
            margin-left: auto;
            background: #2a4a7a;
            padding: 12px 16px;
            border-radius: 12px;
        }

        .message.assistant {
            background: #2a2a2a;
            padding: 12px 16px;
            border-radius: 12px;
        }

        .message.thinking {
            background: #3a2a1a;
            padding: 12px 16px;
            border-radius: 12px;
            border-left: 3px solid #ff8c42;
            opacity: 0.85;
            font-style: italic;
        }

        .thinking-toggle {
            background: #3a2a1a;
            border: 1px solid #4a4a4a;
            color: #ff8c42;
            padding: 6px 10px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            margin: 8px 0;
            display: inline-block;
            user-select: none;
        }

        .thinking-toggle:hover {
            background: #4a3a2a;
        }

        .thinking-content {
            background: #3a2a1a;
            padding: 10px;
            border-radius: 6px;
            border-left: 3px solid #ff8c42;
            margin: 8px 0;
            font-style: italic;
            font-size: 13px;
            color: #d0d0d0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .thinking-content.collapsed {
            display: none;
        }

        .inline-thinking-indicator {
            display: inline-flex;
            align-items: center;
            gap: 4px;
            padding: 4px 8px;
            background: #3a2a1a;
            border-radius: 4px;
            font-size: 11px;
            color: #ff8c42;
            font-style: italic;
            margin: 4px 0;
        }

        .inline-thinking-indicator .dot {
            width: 4px;
            height: 4px;
            background: #ff8c42;
            border-radius: 50%;
            animation: thinking-pulse 1.4s infinite;
        }

        .inline-thinking-indicator .dot:nth-child(2) {
            animation-delay: 0.2s;
        }

        .inline-thinking-indicator .dot:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes thinking-pulse {
            0%, 60%, 100% {
                opacity: 0.3;
            }
            30% {
                opacity: 1;
            }
        }

        .typing-indicator {
            background: #2a2a2a;
            padding: 12px 16px;
            border-radius: 12px;
            max-width: 85%;
            margin-bottom: 20px;
            display: none;
            align-items: center;
            gap: 8px;
            opacity: 0.7;
        }

        .typing-indicator.active {
            display: flex;
        }

        .typing-indicator .dot {
            width: 8px;
            height: 8px;
            background: #4a9eff;
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }

        .typing-indicator .dot:nth-child(2) {
            animation-delay: 0.2s;
        }

        .typing-indicator .dot:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes typing {
            0%, 60%, 100% {
                transform: translateY(0);
                opacity: 0.7;
            }
            30% {
                transform: translateY(-10px);
                opacity: 1;
            }
        }

        .message-content {
            white-space: pre-wrap;
            word-wrap: break-word;
            line-height: 1.5;
        }

        .message-actions {
            margin-top: 8px;
            display: flex;
            gap: 8px;
        }

        .message-actions button {
            background: #3a3a3a;
            border: none;
            color: #888;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            cursor: pointer;
        }

        .message-actions button:hover {
            background: #4a4a4a;
            color: #e0e0e0;
        }

        .file-preview {
            margin-top: 8px;
            max-width: 100%;
        }

        .file-preview img, .file-preview video {
            max-width: 100%;
            border-radius: 8px;
        }

        .file-info {
            background: #3a3a3a;
            padding: 8px;
            border-radius: 4px;
            font-size: 12px;
            margin-top: 8px;
        }

        #chat-input-area {
            background: #2a2a2a;
            border-top: 1px solid #3a3a3a;
            padding: 16px;
        }

        .input-row {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .input-controls, .send-controls {
            display: flex;
            gap: 8px;
        }

        .input-controls {
            width: 100%;
        }

        .input-controls button {
            flex: 1;
        }

        .send-controls {
            width: 100%;
        }

        .send-controls button {
            flex: 1;
        }

        #message-input {
            width: 100%;
            background: #1a1a1a;
            border: 1px solid #3a3a3a;
            color: #e0e0e0;
            padding: 12px;
            border-radius: 8px;
            font-size: 14px;
            font-family: inherit;
            resize: vertical;
            min-height: 44px;
            max-height: 200px;
        }

        #message-input:focus {
            outline: none;
            border-color: #4a9eff;
        }

        .file-upload-btn, .model-select, #send-btn {
            background: #3a3a3a;
            border: 1px solid #4a4a4a;
            color: #e0e0e0;
            padding: 10px 16px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 14px;
        }

        .model-select {
            min-width: 150px;
        }

        #send-btn {
            background: #4a9eff;
            border-color: #4a9eff;
            font-weight: 600;
        }

        #send-btn:hover {
            background: #3a8eef;
        }

        #send-btn:disabled {
            background: #3a3a3a;
            color: #666;
            cursor: not-allowed;
        }

        #stop-btn {
            background: #ff6b6b;
            border-color: #ff6b6b;
            font-weight: 600;
            display: none;
        }

        #stop-btn:hover {
            background: #ff5252;
        }

        .attached-files {
            display: flex;
            gap: 8px;
            margin-bottom: 8px;
            flex-wrap: wrap;
        }

        .attached-file {
            background: #3a3a3a;
            padding: 8px 12px;
            border-radius: 6px;
            font-size: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .attached-file button {
            background: #4a4a4a;
            border: none;
            color: #e0e0e0;
            padding: 2px 6px;
            border-radius: 3px;
            cursor: pointer;
        }

        #model-picker-popup {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.7);
            z-index: 1000;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .popup-content {
            background: #2a2a2a;
            border: 1px solid #4a4a4a;
            border-radius: 8px;
            padding: 20px;
            min-width: 300px;
            max-width: 500px;
            max-height: 80vh;
            overflow-y: auto;
        }

        .popup-content h3 {
            margin-top: 0;
            margin-bottom: 15px;
            color: #e0e0e0;
        }

        #model-checkboxes {
            margin-bottom: 15px;
        }

        #model-checkboxes label {
            display: grid;
            grid-template-columns: auto 1fr;
            gap: 10px;
            align-items: start;
            padding: 8px;
            margin-bottom: 5px;
            background: #3a3a3a;
            border-radius: 4px;
            cursor: pointer;
        }

        #model-checkboxes label:hover {
            background: #4a4a4a;
        }

        #model-checkboxes input[type="checkbox"] {
            margin: 3px 0 0 0;
        }

        .model-info {
            min-width: 0;
        }

        .model-name {
            font-weight: 600;
            color: #e0e0e0;
        }

        .system-prompt-preview {
            font-size: 11px;
            color: #888;
            margin-top: 2px;
            word-wrap: break-word;
        }

        .mode-selector {
            margin-bottom: 15px;
            padding: 10px;
            background: #3a3a3a;
            border-radius: 4px;
        }

        .mode-selector label {
            display: inline-block;
            margin-right: 15px;
            color: #e0e0e0;
        }

        .mode-selector input[type="radio"] {
            margin-right: 5px;
        }

        .settings-container, .prompts-container, .history-container {
            padding: 20px;
            overflow-y: auto;
            flex: 1;
        }

        .settings-section {
            margin-bottom: 24px;
        }

        .settings-section h3 {
            margin-bottom: 12px;
            color: #4a9eff;
        }

        textarea, input, select {
            width: 100%;
            background: #2a2a2a;
            border: 1px solid #3a3a3a;
            color: #e0e0e0;
            padding: 10px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 13px;
        }

        textarea {
            min-height: 200px;
            resize: vertical;
        }

        button.primary {
            background: #4a9eff;
            border: none;
            color: white;
            padding: 10px 20px;
            border-radius: 6px;
            cursor: pointer;
            font-weight: 600;
            margin-top: 12px;
        }

        button.primary:hover {
            background: #3a8eef;
        }

        .prompt-item, .history-item {
            background: #2a2a2a;
            padding: 12px;
            border-radius: 8px;
            margin-bottom: 12px;
            border: 1px solid #3a3a3a;
        }

        .prompt-item h4 {
            margin-bottom: 8px;
            color: #4a9eff;
        }

        .prompt-actions, .history-actions {
            margin-top: 8px;
            display: flex;
            gap: 8px;
        }

        .prompt-actions button, .history-actions button {
            background: #3a3a3a;
            border: none;
            color: #e0e0e0;
            padding: 6px 12px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
        }

        .prompt-actions button:hover, .history-actions button:hover {
            background: #4a4a4a;
        }

        .error {
            background: #4a2a2a;
            border-left: 3px solid #ff4a4a;
            padding: 12px;
            border-radius: 6px;
            margin-bottom: 12px;
        }

        #file-input {
            display: none;
        }

        @media (max-width: 768px) {
            .message {
                max-width: 95%;
            }

            .input-row {
                flex-wrap: wrap;
            }

            .model-select {
                min-width: 100px;
            }
        }
    </style>
</head>
<body>
    <div class="tabs">
        <button class="tab active" data-tab="chat">Chat</button>
        <button class="tab" data-tab="history">History</button>
        <button class="tab" data-tab="help">Help</button>
        <button class="tab" data-tab="settings">Settings</button>
    </div>

    <div id="chat-tab" class="tab-content active">
        <div id="chat-messages"></div>
        <div id="chat-input-area">
            <div class="attached-files" id="attached-files"></div>
            <div class="input-row">
                <input type="file" id="file-input" multiple accept="*/*">
                <div class="input-controls">
                    <button class="file-upload-btn" onclick="document.getElementById('file-input').click()">Attach</button>
                    <button class="model-select" id="model-picker-btn">Select Models</button>
                    <button class="model-select" onclick="newChat()">New Chat</button>
                </div>
                <textarea id="message-input" placeholder="Type a message... (Click Send button to send)"></textarea>
                <div class="send-controls">
                    <button id="send-btn">Send</button>
                    <button id="stop-btn">Stop</button>
                    <button id="auto-btn" style="display: none;">Start Auto</button>
                </div>
            </div>
            <div id="model-picker-popup" style="display: none;">
                <div class="popup-content">
                    <h3>Select Models</h3>
                    <div style="margin-bottom: 15px;">
                        <label style="display: block; margin-bottom: 5px; color: #e0e0e0;">Active System Prompt:</label>
                        <select id="picker-prompt-select" style="width: 100%; padding: 8px; background: #3a3a3a; border: 1px solid #4a4a4a; color: #e0e0e0; border-radius: 4px;">
                            <option value="">None (no system prompt)</option>
                        </select>
                    </div>
                    <div id="model-checkboxes"></div>
                    <div class="mode-selector">
                        <label>Mode:</label>
                        <label><input type="radio" name="model-mode" value="parallel" checked> Parallel</label>
                        <label><input type="radio" name="model-mode" value="serial"> Serial</label>
                        <label><input type="radio" name="model-mode" value="rotating"> Rotating</label>
                        <label><input type="radio" name="model-mode" value="autonomous"> Autonomous</label>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label for="iteration-count">Iterations:</label>
                        <input type="number" id="iteration-count" min="1" max="100" value="1" style="width: 80px; padding: 4px 8px; background: #2a2a2a; border: 1px solid #4a4a4a; color: #e0e0e0; border-radius: 4px;">
                        <span style="font-size: 12px; color: #888; margin-left: 8px;">How many times models should reply</span>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label for="response-delay">Response Delay:</label>
                        <input type="number" id="response-delay" min="0" max="10000" step="100" value="1000" style="width: 80px; padding: 4px 8px; background: #2a2a2a; border: 1px solid #4a4a4a; color: #e0e0e0; border-radius: 4px;">
                        <span style="font-size: 12px; color: #888; margin-left: 8px;">ms delay between responses (Serial/Rotating/Autonomous)</span>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label for="history-limit">Message History Limit:</label>
                        <input type="number" id="history-limit" min="0" max="1000" value="0" style="width: 80px; padding: 4px 8px; background: #2a2a2a; border: 1px solid #4a4a4a; color: #e0e0e0; border-radius: 4px;">
                        <span style="font-size: 12px; color: #888; margin-left: 8px;">0 = all messages</span>
                        <div style="font-size: 11px; color: #666; margin-top: 4px; margin-left: 24px;">
                            Parallel mode: Sends last N messages per model separately<br>
                            Other modes: Sends last N messages (model-agnostic)
                        </div>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label style="display: flex; align-items: center; gap: 8px;">
                            <input type="checkbox" id="include-files-checkbox" style="width: auto;">
                            <span>Include files in message history</span>
                        </label>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label style="display: flex; align-items: center; gap: 8px;">
                            <input type="checkbox" id="enable-identity-checkbox" style="width: auto;">
                            <span>Enable model identity injection (multi-model)</span>
                        </label>
                    </div>
                    <div class="mode-selector" style="margin-top: 10px;">
                        <label style="display: flex; align-items: center; gap: 8px;">
                            <input type="checkbox" id="background-audio-checkbox" style="width: auto;">
                            <span>Keep generating in background (iOS - prevents pause when screen off)</span>
                        </label>
                    </div>
                    <button onclick="closeModelPicker()">Done</button>
                </div>
            </div>
        </div>
    </div>

    <div id="history-tab" class="tab-content">
        <div class="history-container">
            <div class="settings-section">
                <h3>Conversation History</h3>
                <div style="display: flex; gap: 8px; flex-wrap: wrap;">
                    <button class="primary" onclick="exportConversation()">Export History</button>
                    <button class="primary" onclick="document.getElementById('import-history-input').click()">Import History</button>
                    <button class="primary" onclick="clearHistory()">Clear All History</button>
                </div>
                <input type="file" id="import-history-input" accept=".json" style="display: none;" onchange="importHistory(event)">
            </div>
            <div id="history-list"></div>
        </div>
    </div>

    <div id="help-tab" class="tab-content">
        <div class="settings-container">
            <div class="settings-section">
                <h2>OpenRouter Multi-Model Chat - Help & Guide</h2>

                <h3>Quick Start</h3>
                <ol>
                    <li><strong>Add OpenRouter API Key:</strong> Go to Settings → Add API Key section (get your key from openrouter.ai)</li>
                    <li><strong>Browse Models:</strong> Go to Settings → Browse OpenRouter Models → Click "Load Models" to see all available models</li>
                    <li><strong>Add Models:</strong> Click any model from the browser to auto-populate the Add New Model form, or manually add model configuration</li>
                    <li><strong>Select Models:</strong> Click "Select Models" button, check the models you want to use</li>
                    <li><strong>Choose Mode & Iterations:</strong> In model picker, select Parallel/Serial/Rotating/Autonomous and set how many iterations (1-100)</li>
                    <li><strong>Chat:</strong> Type your message and click Send!</li>
                </ol>

                <h3>Model Browser</h3>
                <p>The Browse OpenRouter Models section fetches the live model catalog from OpenRouter:</p>
                <ul>
                    <li><strong>Load Models:</strong> Click to fetch all available models</li>
                    <li><strong>Search:</strong> Filter models by name, ID, or description</li>
                    <li><strong>Sort:</strong> Sort by date (newest first), name, or context length</li>
                    <li><strong>Select:</strong> Click any model to auto-fill the Add New Model form</li>
                </ul>
                <p>Each model shows context length, pricing, and release date to help you choose.</p>

                <h3>Model Configuration</h3>
                <p>Each model is defined by a JSON configuration with NO outer braces. Example:</p>
                <pre style="background: #1a1a1a; padding: 12px; border-radius: 6px; overflow-x: auto;">"endpoint": "https://openrouter.ai/api/v1/chat/completions",
"model_id": "anthropic/claude-3.5-sonnet",
"api_key_id": "123456",
"system_prompt": "",
"max_tokens": null,
"temperature": 1.0</pre>

                <h4>Available OpenRouter Models</h4>
                <p>You can use any model from OpenRouter. Popular options include:</p>
                <ul>
                    <li><code>anthropic/claude-3.5-sonnet</code> - Claude 3.5 Sonnet</li>
                    <li><code>openai/gpt-4-turbo</code> - GPT-4 Turbo</li>
                    <li><code>google/gemini-pro</code> - Google Gemini Pro</li>
                    <li><code>meta-llama/llama-3-70b-instruct</code> - Llama 3 70B</li>
                    <li>...and many more at <a href="https://openrouter.ai/models" target="_blank" style="color: #4a9eff;">openrouter.ai/models</a></li>
                </ul>

                <h4>Per-Model System Prompts</h4>
                <p>Set <code>"system_prompt": "Your prompt here"</code> in each model's config to give it a unique personality.</p>

                <h4>Global System Prompt Override</h4>
                <p>Use the "Active System Prompt" dropdown in the model picker to temporarily override all models' prompts.</p>

                <h3>Multi-Model Modes</h3>
                <ul>
                    <li><strong>Parallel:</strong> All selected models respond independently to your message. Each only sees your messages, not other models' responses.</li>
                    <li><strong>Serial:</strong> Models respond one after another. Each model sees all previous messages including other models' responses.</li>
                    <li><strong>Rotating:</strong> Like Serial, but the order rotates each turn (1,2,3 → 3,1,2 → 2,3,1 → repeat).</li>
                    <li><strong>Autonomous:</strong> Models converse with each other without human input. Click "Start Auto" to begin.</li>
                </ul>

                <h3>Iterations</h3>
                <p>You can set the number of iterations (1-100) to control how many times models reply:</p>
                <ul>
                    <li><strong>Parallel:</strong> All models respond N times in parallel (e.g., 2 iterations = 2 rounds of all models responding simultaneously)</li>
                    <li><strong>Serial:</strong> The complete sequence of models responds N times (e.g., 3 iterations with 2 models = model1, model2, model1, model2, model1, model2)</li>
                    <li><strong>Rotating:</strong> The rotated sequence repeats N times with order continuing to rotate each iteration</li>
                    <li><strong>Autonomous:</strong> Each model responds exactly N times (e.g., 10 iterations with 3 models = 30 total responses, 10 per model)</li>
                </ul>

                <h3>Model Identity System</h3>
                <p>When multiple models are selected, each model automatically receives identity information:</p>
                <ul>
                    <li><strong>Parallel:</strong> "You are [Model Name]. You are conversing with: Human."</li>
                    <li><strong>Serial/Rotating:</strong> "You are [Model Name]. You are conversing with: Human, [Other Models]."</li>
                    <li><strong>Autonomous:</strong> "You are [Model Name]. You are conversing with: [Other Models]." (no Human)</li>
                </ul>

                <h3>About OpenRouter</h3>
                <p>OpenRouter provides unified access to 100+ AI models from multiple providers through a single API:</p>
                <ul>
                    <li><strong>Anthropic:</strong> Claude models (Sonnet, Opus, Haiku)</li>
                    <li><strong>OpenAI:</strong> GPT-4, GPT-3.5, and more</li>
                    <li><strong>Google:</strong> Gemini models</li>
                    <li><strong>Meta:</strong> Llama models</li>
                    <li><strong>Mistral, Cohere, and many others</strong></li>
                </ul>
                <p>Visit <a href="https://openrouter.ai" target="_blank" style="color: #4a9eff;">openrouter.ai</a> to get your API key and browse available models.</p>

                <h3>Advanced Features</h3>
                <h4>Edit AI Responses</h4>
                <p>Click "Edit" button below any AI response to manually modify it before continuing the conversation.</p>

                <h4>Regenerate Responses</h4>
                <p>Click "Regenerate" to have the same model create a different response.</p>

                <h4>Edit User Messages</h4>
                <p>Click "Edit" button on your own messages to revise and branch the conversation from that point.</p>

                <h4>File Attachments</h4>
                <p>Click the "Attach" button to attach images. Support varies by model - most vision-capable models on OpenRouter support image attachments.</p>

                <h4>Image Generation</h4>
                <p>The application supports receiving images from image generation models:</p>
                <ul>
                    <li>Use models with "image" in their output modalities (check model browser or openrouter.ai/models)</li>
                    <li>Request image generation in your message (e.g., "draw a sunset")</li>
                    <li>Generated images appear automatically in the response</li>
                    <li>Multiple images per response are supported</li>
                    <li>Images are displayed inline below the text content</li>
                </ul>

                <h4>OpenRouter Parameters (All Optional)</h4>
                <p>Customize your model behavior with these parameters (set to null to use defaults):</p>
                <ul>
                    <li><code>temperature</code> (0.0-2.0): Randomness/creativity level</li>
                    <li><code>max_tokens</code>: Maximum response length</li>
                    <li><code>top_p</code> (0.0-1.0): Nucleus sampling threshold</li>
                    <li><code>top_k</code>: Limit sampling to top K tokens</li>
                    <li><code>frequency_penalty</code> (-2.0 to 2.0): Reduce word repetition</li>
                    <li><code>presence_penalty</code> (-2.0 to 2.0): Encourage topic diversity</li>
                    <li><code>repetition_penalty</code> (≥0): Alternative repetition control</li>
                    <li><code>min_p</code> (0.0-1.0): Minimum probability threshold</li>
                    <li><code>top_a</code> (0.0-1.0): Adaptive sampling threshold</li>
                    <li><code>seed</code>: For deterministic outputs</li>
                    <li><code>logit_bias</code>: Adjust token probabilities</li>
                    <li><code>response_format</code>: e.g., {"type": "json_object"}</li>
                    <li><code>stop</code>: Array of stop sequences</li>
                    <li><code>tools</code>: Function calling definitions</li>
                    <li><code>tool_choice</code>: Force or disable tool use</li>
                    <li><code>reasoning</code>: Enable extended thinking/reasoning mode with {"effort": "high"|"medium"|"low"} or {"max_tokens": number}</li>
                    <li><code>provider</code>: Force specific provider (e.g., "Anthropic")</li>
                    <li><code>models</code>: Fallback model array</li>
                    <li><code>route</code>: "fallback" to use model list</li>
                    <li><code>transforms</code>: ["middle-out"] for content filtering</li>
                </ul>

                <h3>Data Storage</h3>
                <p>All data is stored locally in your browser using IndexedDB:</p>
                <ul>
                    <li><strong>Storage Capacity:</strong> 50 MB to several GB (varies by browser), much larger than typical localStorage limits</li>
                    <li><strong>Images Supported:</strong> Store conversations with multiple images without quota issues</li>
                    <li><strong>Mobile Friendly:</strong> Works reliably on mobile devices including iPhone/iPad</li>
                    <li><strong>Privacy:</strong> All data stays on your device, nothing sent to servers except OpenRouter API calls</li>
                </ul>

                <h3>Data Management</h3>
                <h4>Export Data</h4>
                <p>Settings → Export Data creates a JSON file with all your models, API keys, prompts, and current conversation.</p>

                <h4>Import Data</h4>
                <p>Settings → Import Data loads a previously exported JSON file.</p>

                <h4>Clear History</h4>
                <p>History → Clear All History removes all saved conversations.</p>

                <h3>Tips & Best Practices</h3>
                <ul>
                    <li><strong>API Keys:</strong> Create separate API key entries for different projects/purposes</li>
                    <li><strong>System Prompts:</strong> Save reusable prompts (e.g., "Coding Assistant", "Creative Writer")</li>
                    <li><strong>Model Names:</strong> Use descriptive names like "GPT-4 Creative" vs "GPT-4 Analytical"</li>
                    <li><strong>Temperature:</strong> Lower (0.0-0.7) for factual/coding, higher (0.8-1.5) for creative</li>
                    <li><strong>Modes:</strong> Use Parallel for comparing responses, Serial for debate/discussion</li>
                </ul>

                <h3>Troubleshooting</h3>
                <p><strong>Messages not sending:</strong> Check browser console (F12) for errors, verify API key is correct</p>
                <p><strong>Images not working:</strong> Ensure you're using a vision-capable model (Claude 3+, GPT-4V, Gemini Pro Vision). Images are always sent with the most recent message.</p>
                <p><strong>Mode not updating:</strong> Hard refresh (Ctrl+Shift+R or Cmd+Shift+R)</p>
                <p><strong>Model deleted:</strong> Can't regenerate old messages from deleted models</p>
                <p><strong>Multiple images on mobile:</strong> IndexedDB storage allows unlimited images even on mobile devices like iPhone</p>

                <h3>Source Code & License</h3>
                <p>This application is open source and available on GitHub:</p>
                <p><a href="https://github.com/mbbrinkman/my_api_chat" target="_blank" style="color: #4a9eff;">https://github.com/mbbrinkman/my_api_chat</a></p>
                <p><strong>License:</strong> CC0 (Public Domain)</p>
                <p>You are free to use, modify, distribute, and do basically whatever you want with this code. No attribution required.</p>
            </div>
        </div>
    </div>

    <div id="settings-tab" class="tab-content">
        <div class="settings-container">
            <div class="settings-section">
                <h3>Add New Prompt</h3>
                <input type="text" id="new-prompt-name" placeholder="Prompt name" style="margin-bottom: 8px;">
                <textarea id="new-prompt-content" placeholder="System prompt content..."></textarea>
                <button class="primary" onclick="addSystemPrompt()">Add Prompt</button>
            </div>
            <div class="settings-section">
                <h3>Saved Prompts</h3>
                <div id="prompts-list"></div>
            </div>
            <div class="settings-section">
                <h3>Add OpenRouter API Key</h3>
                <p style="font-size: 13px; color: #888; margin-bottom: 12px;">Get your API key from <a href="https://openrouter.ai/keys" target="_blank" style="color: #4a9eff;">openrouter.ai/keys</a></p>
                <input type="text" id="new-key-name" placeholder="Key name (e.g., Personal, Work)" style="margin-bottom: 8px;">
                <input type="password" id="new-key-value" placeholder="Paste your OpenRouter API key here" style="margin-bottom: 8px;">
                <button class="primary" onclick="addApiKey()">Add API Key</button>
            </div>
            <div class="settings-section">
                <h3>Saved API Keys</h3>
                <div id="api-keys-list"></div>
            </div>
            <div class="settings-section">
                <h3>Browse OpenRouter Models</h3>
                <p style="font-size: 13px; color: #888; margin-bottom: 12px;">Fetch and search available models from OpenRouter</p>
                <div style="display: flex; gap: 8px; margin-bottom: 8px;">
                    <button class="primary" onclick="fetchOpenRouterModels()">Load Models</button>
                    <select id="model-sort" onchange="sortAndDisplayModels()" style="width: 150px;">
                        <option value="date">Sort by Date</option>
                        <option value="name">Sort by Name</option>
                        <option value="context">Sort by Context</option>
                    </select>
                </div>
                <div style="margin-bottom: 12px;">
                    <input type="text" id="model-search" placeholder="Search models..." style="width: 100%;" oninput="filterModels()">
                </div>
                <div id="models-browser" style="max-height: 400px; overflow-y: auto; background: #1a1a1a; padding: 12px; border-radius: 6px; display: none;">
                    <p style="color: #888;">Click "Load Models" to browse available models</p>
                </div>
            </div>
            <div class="settings-section">
                <h3>Add New Model</h3>
                <input type="text" id="new-model-name" placeholder="Model name (e.g., Claude 3.5 Sonnet)" style="margin-bottom: 8px;">
                <textarea id="new-model-config" placeholder="Model configuration (JSON)..." style="min-height: 250px;"></textarea>
                <button class="primary" onclick="addModel()">Add Model</button>
            </div>
            <div class="settings-section">
                <h3>Saved Models</h3>
                <div id="models-list"></div>
            </div>
            <div class="settings-section">
                <h3>Export/Import Data</h3>
                <button class="primary" onclick="exportData()">Export All Data</button>
                <button class="primary" onclick="document.getElementById('import-input').click()">Import Data</button>
                <input type="file" id="import-input" accept=".json" style="display: none;" onchange="importData(event)">
            </div>
        </div>
    </div>

    <script>
        // State
        let models = [];
        let apiKeys = [];
        let systemPrompts = [];
        let activePromptId = null;
        let currentConversation = [];
        let attachedFiles = [];
        let editingMessageIndex = null;
        let isStreaming = false;
        let selectedModelIndices = [];
        let multiModelMode = 'parallel';
        let rotationIndex = 0;
        let isAutonomousRunning = false;
        let autonomousRounds = 0;
        let iterationCount = 1;
        let messageHistoryLimit = 0; // 0 means all messages
        let includeFilesInHistory = false;
        let responseDelay = 1000; // Delay in ms between responses in serial/rotating/autonomous modes
        let enableModelIdentity = true; // Whether to inject model identity into system prompts
        let enableBackgroundAudio = false; // Whether to play silent audio to keep app alive on iOS
        let availableModels = [];
        let filteredModels = [];
        let currentAbortControllers = [];
        let conversationHistory = []; // Array to store saved conversations

        // Background audio to prevent iOS from pausing when screen is off
        let audioContext = null;
        let silentAudioNode = null;

        // Initialize
        async function init() {
            await loadFromStorage();
            setupEventListeners();
            updateModelSelect();
            updateModelsList();
            updateApiKeysList();
            updatePromptsList();
            renderConversation();
            renderHistory();
        }

        // IndexedDB wrapper for storage
        let db = null;

        async function initDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open('ApiChatDB', 1);

                request.onerror = () => reject(request.error);
                request.onsuccess = () => {
                    db = request.result;
                    resolve(db);
                };

                request.onupgradeneeded = (event) => {
                    const db = event.target.result;
                    if (!db.objectStoreNames.contains('settings')) {
                        db.createObjectStore('settings');
                    }
                };
            });
        }

        async function saveData(key, value) {
            if (!db) await initDB();
            return new Promise((resolve, reject) => {
                const transaction = db.transaction(['settings'], 'readwrite');
                const store = transaction.objectStore('settings');
                const request = store.put(value, key);
                request.onsuccess = () => resolve();
                request.onerror = () => reject(request.error);
            });
        }

        async function loadData(key, defaultValue = null) {
            if (!db) await initDB();
            return new Promise((resolve, reject) => {
                const transaction = db.transaction(['settings'], 'readonly');
                const store = transaction.objectStore('settings');
                const request = store.get(key);
                request.onsuccess = () => {
                    resolve(request.result !== undefined ? request.result : defaultValue);
                };
                request.onerror = () => reject(request.error);
            });
        }

        async function loadFromStorage() {
            try {
                await initDB();

                models = await loadData('models', []);
                apiKeys = await loadData('apiKeys', []);
                systemPrompts = await loadData('systemPrompts', []);
                activePromptId = await loadData('activePromptId', null);
                currentConversation = await loadData('currentConversation', []);
                selectedModelIndices = await loadData('selectedModelIndices', []);
                multiModelMode = await loadData('multiModelMode', 'parallel');
                rotationIndex = await loadData('rotationIndex', 0);
                iterationCount = await loadData('iterationCount', 1);
                messageHistoryLimit = await loadData('messageHistoryLimit', 0);
                includeFilesInHistory = await loadData('includeFilesInHistory', false);
                responseDelay = await loadData('responseDelay', 1000);
                enableModelIdentity = await loadData('enableModelIdentity', true);
                enableBackgroundAudio = await loadData('enableBackgroundAudio', false);
                conversationHistory = await loadData('conversationHistory', []);
            } catch (e) {
                console.error('Error loading from IndexedDB:', e);
            }
        }

        async function saveToStorage() {
            try {
                await Promise.all([
                    saveData('models', models),
                    saveData('apiKeys', apiKeys),
                    saveData('systemPrompts', systemPrompts),
                    saveData('activePromptId', activePromptId),
                    saveData('currentConversation', currentConversation),
                    saveData('selectedModelIndices', selectedModelIndices),
                    saveData('multiModelMode', multiModelMode),
                    saveData('rotationIndex', rotationIndex),
                    saveData('iterationCount', iterationCount),
                    saveData('messageHistoryLimit', messageHistoryLimit),
                    saveData('includeFilesInHistory', includeFilesInHistory),
                    saveData('responseDelay', responseDelay),
                    saveData('enableModelIdentity', enableModelIdentity),
                    saveData('enableBackgroundAudio', enableBackgroundAudio),
                    saveData('conversationHistory', conversationHistory)
                ]);
            } catch (e) {
                console.error('Error saving to IndexedDB:', e);
            }
        }

        function startBackgroundAudio() {
            if (!enableBackgroundAudio) return;

            try {
                if (!audioContext) {
                    // Create audio context
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Resume context if suspended (needed for iOS)
                if (audioContext.state === 'suspended') {
                    audioContext.resume();
                }

                if (!silentAudioNode) {
                    // Create a very quiet oscillator (barely audible)
                    const oscillator = audioContext.createOscillator();
                    const gainNode = audioContext.createGain();

                    // Set to extremely low volume (essentially silent)
                    gainNode.gain.value = 0.0001;

                    // Connect nodes
                    oscillator.connect(gainNode);
                    gainNode.connect(audioContext.destination);

                    // Start oscillator
                    oscillator.start();

                    silentAudioNode = { oscillator, gainNode };
                }
            } catch (e) {
                console.error('Error starting background audio:', e);
            }
        }

        function stopBackgroundAudio() {
            try {
                if (silentAudioNode) {
                    silentAudioNode.oscillator.stop();
                    silentAudioNode.oscillator.disconnect();
                    silentAudioNode.gainNode.disconnect();
                    silentAudioNode = null;
                }

                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.suspend();
                }
            } catch (e) {
                console.error('Error stopping background audio:', e);
            }
        }

        function setupEventListeners() {
            // Tab switching
            document.querySelectorAll('.tab').forEach(tab => {
                tab.addEventListener('click', () => {
                    const tabName = tab.dataset.tab;
                    switchTab(tabName);
                });
            });

            // Send message
            document.getElementById('send-btn').addEventListener('click', sendMessage);

            // Stop generation
            document.getElementById('stop-btn').addEventListener('click', stopGeneration);

            // File upload
            document.getElementById('file-input').addEventListener('change', handleFileUpload);

            // Model picker button
            document.getElementById('model-picker-btn').addEventListener('click', openModelPicker);

            // Model picker popup - click outside to close
            document.getElementById('model-picker-popup').addEventListener('click', (e) => {
                if (e.target.id === 'model-picker-popup') {
                    closeModelPicker();
                }
            });

            // Model mode radio buttons
            document.querySelectorAll('input[name="model-mode"]').forEach(radio => {
                radio.addEventListener('change', (e) => {
                    multiModelMode = e.target.value;
                    updateUIForMode();
                    updateModelPickerButton();
                    saveToStorage();
                });
            });

            // Iteration count input
            const iterationInput = document.getElementById('iteration-count');
            if (iterationInput) {
                iterationInput.addEventListener('change', (e) => {
                    const value = parseInt(e.target.value);
                    if (value >= 1 && value <= 100) {
                        iterationCount = value;
                        saveToStorage();
                    } else {
                        e.target.value = iterationCount;
                    }
                });
            }

            // Response delay input
            const delayInput = document.getElementById('response-delay');
            if (delayInput) {
                delayInput.addEventListener('change', (e) => {
                    const value = parseInt(e.target.value);
                    if (value >= 0 && value <= 10000) {
                        responseDelay = value;
                        saveToStorage();
                    } else {
                        e.target.value = responseDelay;
                    }
                });
            }

            // Message history limit input
            const historyLimitInput = document.getElementById('history-limit');
            if (historyLimitInput) {
                historyLimitInput.addEventListener('change', (e) => {
                    const value = parseInt(e.target.value);
                    if (value >= 0 && value <= 1000) {
                        messageHistoryLimit = value;
                        saveToStorage();
                    } else {
                        e.target.value = messageHistoryLimit;
                    }
                });
            }

            // Include files checkbox
            const includeFilesCheckbox = document.getElementById('include-files-checkbox');
            if (includeFilesCheckbox) {
                includeFilesCheckbox.addEventListener('change', (e) => {
                    includeFilesInHistory = e.target.checked;
                    saveToStorage();
                });
            }

            // Enable model identity checkbox
            const enableIdentityCheckbox = document.getElementById('enable-identity-checkbox');
            if (enableIdentityCheckbox) {
                enableIdentityCheckbox.addEventListener('change', (e) => {
                    enableModelIdentity = e.target.checked;
                    saveToStorage();
                });
            }

            const backgroundAudioCheckbox = document.getElementById('background-audio-checkbox');
            if (backgroundAudioCheckbox) {
                backgroundAudioCheckbox.addEventListener('change', (e) => {
                    enableBackgroundAudio = e.target.checked;
                    saveToStorage();
                    // Stop audio if disabled while running
                    if (!enableBackgroundAudio) {
                        stopBackgroundAudio();
                    }
                });
            }

            // Autonomous button
            document.getElementById('auto-btn').addEventListener('click', toggleAutonomous);

            // Pre-populate OpenRouter config
            updateModelConfigTemplate();
        }

        function updateModelConfigTemplate() {
            const configTextarea = document.getElementById('new-model-config');
            const openrouterKeys = apiKeys.filter(k => k.provider === 'openrouter');
            const apiKeyRef = openrouterKeys.length > 0
                ? `"api_key_id": "${openrouterKeys[0].id}"`
                : `"api_key": "your-openrouter-api-key-here"`;

            configTextarea.value = `"endpoint": "https://openrouter.ai/api/v1/chat/completions",
  "model_id": "anthropic/claude-3.5-sonnet",
  ${apiKeyRef},
  "system_prompt": "",
  "max_tokens": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "top_k": 0,
  "frequency_penalty": 0,
  "presence_penalty": 0,
  "repetition_penalty": 1,
  "min_p": 0,
  "top_a": 0,
  "seed": null,
  "logit_bias": null,
  "logprobs": null,
  "top_logprobs": null,
  "response_format": null,
  "stop": null,
  "tools": null,
  "tool_choice": null,
  "reasoning": {
    "effort": "medium"
  },
  "provider": null,
  "models": null,
  "route": null,
  "transforms": null
`;
        }

        function switchTab(tabName) {
            document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
            document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
            
            document.querySelector(`[data-tab="${tabName}"]`).classList.add('active');
            document.getElementById(`${tabName}-tab`).classList.add('active');

            if (tabName === 'settings') {
                updateModelsList();
                updateApiKeysList();
                updatePromptsList();
                updateModelConfigTemplate();
            }
        }

        function updateModelSelect() {
            updateModelPickerButton();
        }

        function updateModelPickerButton() {
            const btn = document.getElementById('model-picker-btn');
            if (selectedModelIndices.length === 0) {
                btn.textContent = 'Select Models';
            } else if (selectedModelIndices.length === 1) {
                btn.textContent = models[selectedModelIndices[0]]?.name || 'Select Models';
            } else {
                btn.textContent = `${selectedModelIndices.length} Models (${multiModelMode})`;
            }
        }

        function openModelPicker() {
            const popup = document.getElementById('model-picker-popup');
            const checkboxesContainer = document.getElementById('model-checkboxes');

            // Populate system prompt selector
            const promptSelect = document.getElementById('picker-prompt-select');
            promptSelect.innerHTML = '<option value="">None (no system prompt)</option>';
            systemPrompts.forEach(prompt => {
                const option = document.createElement('option');
                option.value = prompt.id;
                option.textContent = prompt.name;
                if (prompt.id === activePromptId) {
                    option.selected = true;
                }
                promptSelect.appendChild(option);
            });
            promptSelect.onchange = (e) => {
                activePromptId = e.target.value || null;
                saveToStorage();
            };

            checkboxesContainer.innerHTML = '';

            if (models.length === 0) {
                checkboxesContainer.innerHTML = '<p style="color: #888;">No models configured. Add models in Settings.</p>';
            } else {
                models.forEach((model, index) => {
                    const label = document.createElement('label');
                    const checkbox = document.createElement('input');
                    checkbox.type = 'checkbox';
                    checkbox.value = index;
                    checkbox.checked = selectedModelIndices.includes(index);
                    checkbox.addEventListener('change', (e) => {
                        if (e.target.checked) {
                            if (!selectedModelIndices.includes(index)) {
                                selectedModelIndices.push(index);
                            }
                        } else {
                            selectedModelIndices = selectedModelIndices.filter(i => i !== index);
                        }
                        saveToStorage();
                        updateModelPickerButton();
                    });

                    label.appendChild(checkbox);

                    // Create a div for model info
                    const modelInfo = document.createElement('div');
                    modelInfo.className = 'model-info';

                    const modelName = document.createElement('div');
                    modelName.className = 'model-name';
                    modelName.textContent = model.name;
                    modelInfo.appendChild(modelName);

                    // Show active system prompt (global overrides per-model)
                    let promptText = null;
                    if (activePromptId) {
                        const prompt = systemPrompts.find(p => p.id === activePromptId);
                        if (prompt) {
                            promptText = prompt.content;
                        }
                    } else if (model.system_prompt && model.system_prompt.trim()) {
                        promptText = model.system_prompt;
                    }

                    if (promptText) {
                        const promptPreview = document.createElement('div');
                        promptPreview.className = 'system-prompt-preview';
                        const previewText = promptText.length > 60
                            ? promptText.substring(0, 60) + '...'
                            : promptText;
                        promptPreview.textContent = `System: ${previewText}`;
                        modelInfo.appendChild(promptPreview);
                    }

                    label.appendChild(modelInfo);
                    checkboxesContainer.appendChild(label);
                });
            }

            // Set the current mode
            document.querySelectorAll('input[name="model-mode"]').forEach(radio => {
                radio.checked = (radio.value === multiModelMode);
            });

            // Set the iteration count
            const iterationInput = document.getElementById('iteration-count');
            if (iterationInput) {
                iterationInput.value = iterationCount;
            }

            // Set the response delay
            const delayInput = document.getElementById('response-delay');
            if (delayInput) {
                delayInput.value = responseDelay;
            }

            // Set the history limit
            const historyLimitInput = document.getElementById('history-limit');
            if (historyLimitInput) {
                historyLimitInput.value = messageHistoryLimit;
            }

            // Set the include files checkbox
            const includeFilesCheckbox = document.getElementById('include-files-checkbox');
            if (includeFilesCheckbox) {
                includeFilesCheckbox.checked = includeFilesInHistory;
            }

            // Set the enable identity checkbox
            const enableIdentityCheckbox = document.getElementById('enable-identity-checkbox');
            if (enableIdentityCheckbox) {
                enableIdentityCheckbox.checked = enableModelIdentity;
            }

            // Set the background audio checkbox
            const backgroundAudioCheckbox = document.getElementById('background-audio-checkbox');
            if (backgroundAudioCheckbox) {
                backgroundAudioCheckbox.checked = enableBackgroundAudio;
            }

            popup.style.display = 'flex';
        }

        function closeModelPicker() {
            document.getElementById('model-picker-popup').style.display = 'none';
            updateUIForMode();
        }

        function updateUIForMode() {
            const autoBtn = document.getElementById('auto-btn');
            const sendBtn = document.getElementById('send-btn');
            const messageInput = document.getElementById('message-input');

            if (multiModelMode === 'autonomous') {
                autoBtn.style.display = 'block';
                sendBtn.style.display = 'none';
                messageInput.disabled = true;
                messageInput.placeholder = 'Autonomous mode - models will converse automatically';
                updateModelPickerButton();
            } else {
                autoBtn.style.display = 'none';
                sendBtn.style.display = 'block';
                messageInput.disabled = false;
                messageInput.placeholder = 'Type a message... (Click Send button to send)';
            }
        }

        async function toggleAutonomous() {
            const autoBtn = document.getElementById('auto-btn');

            if (isAutonomousRunning) {
                isAutonomousRunning = false;
                autoBtn.textContent = 'Start Auto';
                autoBtn.style.background = '#4a9eff';
                return;
            }

            if (selectedModelIndices.length < 2) {
                alert('Please select at least 2 models for autonomous mode');
                return;
            }

            // If conversation is empty, add a starter message for autonomous mode
            if (currentConversation.length === 0) {
                const starterMessage = {
                    role: 'user',
                    content: 'Begin your conversation.',
                    timestamp: Date.now()
                };
                currentConversation.push(starterMessage);
                saveToStorage();
                renderConversation();
            }

            isAutonomousRunning = true;
            autonomousRounds = 0;
            autoBtn.textContent = 'Stop Auto';
            autoBtn.style.background = '#ff4a4a';

            // Run for iterationCount rounds per model (or until stopped manually)
            // Total rounds = iterationCount * number of models
            while (isAutonomousRunning && autonomousRounds < (iterationCount * selectedModelIndices.length)) {
                try {
                    await handleAutonomousRound();
                    autonomousRounds++;

                    // Delay between rounds (configurable)
                    if (responseDelay > 0 && autonomousRounds < (iterationCount * selectedModelIndices.length)) {
                        await new Promise(resolve => setTimeout(resolve, responseDelay));
                    }
                } catch (error) {
                    console.error('Autonomous error:', error);

                    // Remove any empty assistant messages that were added before the error
                    currentConversation = currentConversation.filter(msg => {
                        if (msg.role === 'assistant') {
                            return msg.content || msg.thinking || (msg.images && msg.images.length > 0);
                        }
                        return true;
                    });

                    isAutonomousRunning = false;
                    autoBtn.textContent = 'Start Auto';
                    autoBtn.style.background = '#4a9eff';
                    saveToStorage();
                    renderConversation();
                    alert('Error in autonomous mode: ' + error.message);
                }
            }

            // Final cleanup: Remove any empty assistant messages
            currentConversation = currentConversation.filter(msg => {
                if (msg.role === 'assistant') {
                    return msg.content || msg.thinking || (msg.images && msg.images.length > 0);
                }
                return true;
            });

            // Reset button when done (either completed iterations or stopped manually)
            isAutonomousRunning = false;
            autoBtn.textContent = 'Start Auto';
            autoBtn.style.background = '#4a9eff';
            saveToStorage();
            renderConversation();
        }

        function updatePromptsList() {
            const list = document.getElementById('prompts-list');
            list.innerHTML = '';

            if (systemPrompts.length === 0) {
                list.innerHTML = '<p style="color: #888;">No saved prompts yet.</p>';
                return;
            }

            systemPrompts.forEach(prompt => {
                const div = document.createElement('div');
                div.className = 'prompt-item';
                div.innerHTML = `
                    <h4>${escapeHtml(prompt.name)}</h4>
                    <div style="white-space: pre-wrap; font-size: 13px; color: #aaa;">${escapeHtml(prompt.content.substring(0, 200))}${prompt.content.length > 200 ? '...' : ''}</div>
                    <div class="prompt-actions">
                        <button onclick="editPrompt('${prompt.id}')">Edit</button>
                        <button onclick="deletePrompt('${prompt.id}')">Delete</button>
                    </div>
                `;
                list.appendChild(div);
            });
        }

        function addSystemPrompt() {
            const name = document.getElementById('new-prompt-name').value.trim();
            const content = document.getElementById('new-prompt-content').value.trim();

            if (!name || !content) {
                alert('Please enter both name and content');
                return;
            }

            const prompt = {
                id: Date.now().toString(),
                name,
                content
            };

            systemPrompts.push(prompt);
            saveToStorage();
            updatePromptsList();

            document.getElementById('new-prompt-name').value = '';
            document.getElementById('new-prompt-content').value = '';
        }

        function editPrompt(id) {
            const prompt = systemPrompts.find(p => p.id === id);
            if (!prompt) return;

            document.getElementById('new-prompt-name').value = prompt.name;
            document.getElementById('new-prompt-content').value = prompt.content;

            // Delete the old prompt
            deletePrompt(id);

            // Scroll to the form
            document.querySelector('#new-prompt-name').scrollIntoView({ behavior: 'smooth' });
        }

        function deletePrompt(id) {
            if (!confirm('Delete this prompt?')) return;
            systemPrompts = systemPrompts.filter(p => p.id !== id);
            if (activePromptId === id) {
                activePromptId = null;
            }
            saveToStorage();
            updatePromptsList();
        }

        function addApiKey() {
            const name = document.getElementById('new-key-name').value.trim();
            const value = document.getElementById('new-key-value').value.trim();

            if (!name || !value) {
                alert('Please fill in all fields');
                return;
            }

            const apiKey = {
                id: Date.now().toString(),
                name,
                provider: 'openrouter',  // Always OpenRouter
                value
            };

            apiKeys.push(apiKey);
            saveToStorage();
            updateApiKeysList();
            updateModelConfigTemplate();  // Update model template with new key

            // Clear form
            document.getElementById('new-key-name').value = '';
            document.getElementById('new-key-value').value = '';

            alert('API key added successfully!');
        }

        function deleteApiKey(id) {
            if (!confirm('Delete this API key?')) return;
            apiKeys = apiKeys.filter(k => k.id !== id);
            saveToStorage();
            updateApiKeysList();
            updateModelConfigTemplate();  // Update template after deleting key
        }

        function updateApiKeysList() {
            const list = document.getElementById('api-keys-list');
            list.innerHTML = '';

            if (apiKeys.length === 0) {
                list.innerHTML = '<p style="color: #888;">No API keys saved yet.</p>';
                return;
            }

            apiKeys.forEach(key => {
                const div = document.createElement('div');
                div.className = 'prompt-item';
                div.innerHTML = `
                    <h4>${escapeHtml(key.name)}</h4>
                    <div style="font-size: 12px; color: #666; margin-bottom: 8px;">
                        ID: ${escapeHtml(key.id)}
                    </div>
                    <div style="font-size: 13px; color: #aaa; margin-bottom: 4px;">
                        <strong>Provider:</strong> ${escapeHtml(key.provider)}<br>
                        <strong>Key:</strong> ${escapeHtml(key.value.substring(0, 10))}...${escapeHtml(key.value.substring(key.value.length - 4))}
                    </div>
                    <div class="prompt-actions">
                        <button onclick="deleteApiKey('${key.id}')">Delete</button>
                    </div>
                `;
                list.appendChild(div);
            });
        }

        function addModel() {
            const name = document.getElementById('new-model-name').value.trim();
            const configText = document.getElementById('new-model-config').value.trim();

            if (!name) {
                alert('Please enter a model name');
                return;
            }

            if (!configText) {
                alert('Please select a template or enter model configuration');
                return;
            }

            try {
                // Wrap in {} if not already wrapped
                const jsonText = configText.trim().startsWith('{')
                    ? configText
                    : `{${configText}}`;

                const config = JSON.parse(jsonText);

                // Validate required fields
                if (!config.endpoint || !config.model_id || (!config.api_key && !config.api_key_id)) {
                    alert('Configuration must include: endpoint, model_id, and api_key (or api_key_id)');
                    return;
                }

                const model = {
                    name,
                    ...config
                };

                models.push(model);
                saveToStorage();
                updateModelSelect();
                updateModelsList();

                // Clear form
                document.getElementById('new-model-name').value = '';
                document.getElementById('new-model-config').value = '';

                alert('Model added successfully!');
            } catch (e) {
                alert('Invalid JSON configuration: ' + e.message);
            }
        }

        function editModel(index) {
            const model = models[index];
            const { name, ...config } = model;

            document.getElementById('new-model-name').value = name;

            // Convert config back to formatted JSON without outer braces
            const configJson = JSON.stringify(config, null, 2);
            const withoutBraces = configJson.substring(1, configJson.length - 1).trim();
            document.getElementById('new-model-config').value = withoutBraces;

            // Delete the old model
            deleteModel(index);

            // Scroll to the form
            document.querySelector('#new-model-name').scrollIntoView({ behavior: 'smooth' });
        }

        function deleteModel(index) {
            if (!confirm('Delete this model?')) return;
            models.splice(index, 1);

            // Update selectedModelIndices to remove this index and adjust higher indices
            selectedModelIndices = selectedModelIndices
                .filter(i => i !== index)
                .map(i => i > index ? i - 1 : i);

            saveToStorage();
            updateModelSelect();
            updateModelsList();
        }

        function updateModelsList() {
            const list = document.getElementById('models-list');
            list.innerHTML = '';

            if (models.length === 0) {
                list.innerHTML = '<p style="color: #888;">No models configured yet.</p>';
                return;
            }

            models.forEach((model, index) => {
                const div = document.createElement('div');
                div.className = 'prompt-item';

                // Create config object without the name field for display
                const { name, ...config } = model;
                const configJson = JSON.stringify(config, null, 2);

                div.innerHTML = `
                    <h4>${escapeHtml(model.name)}</h4>
                    <div style="font-size: 13px; color: #aaa; margin-bottom: 8px;">
                        <strong>Model ID:</strong> ${escapeHtml(model.model_id)}
                    </div>
                    <details style="margin-bottom: 8px;">
                        <summary style="cursor: pointer; color: #4a9eff; font-size: 13px;">View Configuration</summary>
                        <pre style="background: #1a1a1a; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 12px; margin-top: 8px;">${escapeHtml(configJson)}</pre>
                    </details>
                    <div class="prompt-actions">
                        <button onclick="editModel(${index})">Edit</button>
                        <button onclick="deleteModel(${index})">Delete</button>
                    </div>
                `;
                list.appendChild(div);
            });
        }

        async function fetchOpenRouterModels() {
            const browser = document.getElementById('models-browser');
            browser.style.display = 'block';
            browser.innerHTML = '<p style="color: #888;">Loading models from OpenRouter...</p>';

            try {
                const response = await fetch('https://openrouter.ai/api/v1/models');
                if (!response.ok) {
                    throw new Error(`Failed to fetch models: ${response.status}`);
                }

                const data = await response.json();
                availableModels = data.data || [];
                filteredModels = [...availableModels];

                sortAndDisplayModels();
            } catch (error) {
                browser.innerHTML = `<p style="color: #ff6b6b;">Error loading models: ${escapeHtml(error.message)}</p>`;
                console.error('Error fetching models:', error);
            }
        }

        function filterModels() {
            const searchTerm = document.getElementById('model-search').value.toLowerCase();

            if (!searchTerm) {
                filteredModels = [...availableModels];
            } else {
                filteredModels = availableModels.filter(model => {
                    const searchText = `${model.id} ${model.name || ''} ${model.description || ''}`.toLowerCase();
                    return searchText.includes(searchTerm);
                });
            }

            sortAndDisplayModels();
        }

        function sortAndDisplayModels() {
            const sortBy = document.getElementById('model-sort').value;

            // Sort
            filteredModels.sort((a, b) => {
                if (sortBy === 'date') {
                    const dateA = new Date(a.created || 0);
                    const dateB = new Date(b.created || 0);
                    return dateB - dateA; // Newest first
                } else if (sortBy === 'name') {
                    return (a.name || a.id).localeCompare(b.name || b.id);
                } else if (sortBy === 'context') {
                    return (b.context_length || 0) - (a.context_length || 0); // Largest first
                }
                return 0;
            });

            displayModels();
        }

        function displayModels() {
            const browser = document.getElementById('models-browser');

            if (filteredModels.length === 0) {
                browser.innerHTML = '<p style="color: #888;">No models found matching your search.</p>';
                return;
            }

            let html = `<div style="font-size: 13px; color: #888; margin-bottom: 12px;">Found ${filteredModels.length} models. Click to select.</div>`;

            filteredModels.forEach(model => {
                const pricing = model.pricing || {};
                const promptPrice = pricing.prompt ? `$${(parseFloat(pricing.prompt) * 1000000).toFixed(2)}/M` : 'N/A';
                const completionPrice = pricing.completion ? `$${(parseFloat(pricing.completion) * 1000000).toFixed(2)}/M` : 'N/A';
                const contextLength = model.context_length ? `${(model.context_length / 1000).toFixed(0)}K` : 'N/A';
                const created = model.created ? new Date(model.created * 1000).toLocaleDateString() : 'Unknown';

                html += `
                    <div style="background: #2a2a2a; padding: 12px; border-radius: 6px; margin-bottom: 8px; cursor: pointer; border: 2px solid transparent;"
                         onclick="selectModel('${escapeHtml(model.id)}', '${escapeHtml(model.name || model.id)}')"
                         onmouseover="this.style.borderColor='#4a9eff'"
                         onmouseout="this.style.borderColor='transparent'">
                        <div style="font-weight: 600; color: #e0e0e0; margin-bottom: 4px;">${escapeHtml(model.name || model.id)}</div>
                        <div style="font-size: 12px; color: #888; font-family: monospace; margin-bottom: 6px;">${escapeHtml(model.id)}</div>
                        <div style="font-size: 12px; color: #aaa; margin-bottom: 6px;">${escapeHtml(model.description || 'No description')}</div>
                        <div style="font-size: 11px; color: #666; display: flex; gap: 12px;">
                            <span>Context: ${contextLength}</span>
                            <span>Prompt: ${promptPrice}</span>
                            <span>Completion: ${completionPrice}</span>
                            <span>Released: ${created}</span>
                        </div>
                    </div>
                `;
            });

            browser.innerHTML = html;
        }

        function selectModel(modelId, modelName) {
            // Populate the Add New Model form
            document.getElementById('new-model-name').value = modelName;

            // Get the current config template
            const configTextarea = document.getElementById('new-model-config');
            let currentConfig = configTextarea.value;

            // Replace the model_id in the template
            currentConfig = currentConfig.replace(
                /"model_id":\s*"[^"]*"/,
                `"model_id": "${modelId}"`
            );

            configTextarea.value = currentConfig;

            // Scroll to the Add New Model section
            document.querySelector('#new-model-name').scrollIntoView({ behavior: 'smooth', block: 'center' });

            // Flash the textarea to show it was updated
            configTextarea.style.border = '2px solid #4a9eff';
            setTimeout(() => {
                configTextarea.style.border = '';
            }, 1000);
        }

        async function handleFileUpload(e) {
            const files = Array.from(e.target.files);
            
            for (const file of files) {
                const base64 = await fileToBase64(file);
                attachedFiles.push({
                    name: file.name,
                    type: file.type,
                    size: file.size,
                    base64: base64.split(',')[1] // Remove data URL prefix
                });
            }

            renderAttachedFiles();
            e.target.value = ''; // Reset input
        }

        function fileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        }

        function renderAttachedFiles() {
            const container = document.getElementById('attached-files');
            container.innerHTML = '';

            attachedFiles.forEach((file, index) => {
                const div = document.createElement('div');
                div.className = 'attached-file';
                div.innerHTML = `
                    <span>${escapeHtml(file.name)} (${formatFileSize(file.size)})</span>
                    <button onclick="removeAttachedFile(${index})">✕</button>
                `;
                container.appendChild(div);
            });
        }

        function removeAttachedFile(index) {
            attachedFiles.splice(index, 1);
            renderAttachedFiles();
        }

        function formatFileSize(bytes) {
            if (bytes < 1024) return bytes + ' B';
            if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
            return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
        }

        function showStopButton() {
            document.getElementById('send-btn').style.display = 'none';
            document.getElementById('stop-btn').style.display = 'block';
        }

        function hideStopButton() {
            document.getElementById('stop-btn').style.display = 'none';
            document.getElementById('send-btn').style.display = 'block';
        }

        function stopGeneration() {
            // Abort all ongoing requests
            currentAbortControllers.forEach(controller => {
                try {
                    controller.abort();
                } catch (e) {
                    console.error('Error aborting request:', e);
                }
            });
            currentAbortControllers = [];

            // Reset UI state
            isStreaming = false;
            stopBackgroundAudio(); // Stop silent audio when stopped
            hideStopButton();
            document.getElementById('send-btn').disabled = false;
        }

        async function sendMessage() {
            if (isStreaming) return;

            const input = document.getElementById('message-input');
            const messageText = input.value.trim();

            if (!messageText && attachedFiles.length === 0) return;
            if (models.length === 0) {
                alert('Please configure at least one model in Settings');
                return;
            }

            if (selectedModelIndices.length === 0) {
                alert('Please select at least one model');
                return;
            }

            const userMessage = {
                role: 'user',
                content: messageText,
                files: attachedFiles.length > 0 ? [...attachedFiles] : null,
                timestamp: Date.now()
            };

            if (editingMessageIndex !== null) {
                currentConversation = currentConversation.slice(0, editingMessageIndex);
                currentConversation.push(userMessage);
                editingMessageIndex = null;
            } else {
                currentConversation.push(userMessage);
            }

            input.value = '';
            attachedFiles = [];
            renderAttachedFiles();
            renderConversation();
            saveToStorage();

            // Start streaming response
            isStreaming = true;
            currentAbortControllers = [];
            showStopButton();
            startBackgroundAudio(); // Keep iOS active during generation
            renderConversation();

            try {
                if (multiModelMode === 'parallel') {
                    await handleParallelMode();
                } else if (multiModelMode === 'serial') {
                    await handleSerialMode();
                } else if (multiModelMode === 'rotating') {
                    await handleRotatingMode();
                }
            } catch (error) {
                console.error('Error:', error);

                // Remove any empty assistant messages that were added before the error
                currentConversation = currentConversation.filter(msg => {
                    if (msg.role === 'assistant') {
                        // Keep messages that have content, thinking, or images
                        return msg.content || msg.thinking || (msg.images && msg.images.length > 0);
                    }
                    return true; // Keep all user messages
                });

                // Add user-friendly error message
                const errorMessage = {
                    role: 'assistant',
                    content: `Error: ${error.message}\n\nTroubleshooting:\n• Check your API key in Settings\n• Verify your model configuration\n• Ensure you have internet connection`,
                    timestamp: Date.now()
                };
                currentConversation.push(errorMessage);
                renderConversation();
            }

            // Final cleanup: Remove any empty assistant messages that may have slipped through
            currentConversation = currentConversation.filter(msg => {
                if (msg.role === 'assistant') {
                    return msg.content || msg.thinking || (msg.images && msg.images.length > 0);
                }
                return true;
            });

            isStreaming = false;
            stopBackgroundAudio(); // Stop silent audio when done
            currentAbortControllers = [];
            hideStopButton();
            renderConversation();
            saveToStorage();
        }

        async function handleParallelMode() {
            // All models answer independently in parallel, repeated for iterationCount times
            for (let iteration = 0; iteration < iterationCount; iteration++) {
                const promises = selectedModelIndices.map(async (modelIndex) => {
                    const model = models[modelIndex];
                    const assistantMessage = {
                        role: 'assistant',
                        content: '',
                        thinking: '',
                        images: [],
                        modelName: model.name,
                        timestamp: Date.now()
                    };
                    currentConversation.push(assistantMessage);
                    renderConversation();
                    await streamResponse(model, assistantMessage);
                });

                await Promise.all(promises);

                // Save after each iteration completes
                saveToStorage();
                renderConversation();
            }
        }

        async function handleSerialMode() {
            // Models answer sequentially, each seeing previous responses, repeated for iterationCount times
            for (let iteration = 0; iteration < iterationCount; iteration++) {
                for (let i = 0; i < selectedModelIndices.length; i++) {
                    const modelIndex = selectedModelIndices[i];
                    const model = models[modelIndex];
                    const assistantMessage = {
                        role: 'assistant',
                        content: '',
                        thinking: '',
                        images: [],
                        modelName: model.name,
                        timestamp: Date.now()
                    };
                    currentConversation.push(assistantMessage);
                    renderConversation();
                    await streamResponse(model, assistantMessage);

                    // Save and render after each model completes so next model sees the response
                    saveToStorage();
                    renderConversation();

                    // Add delay before next model (unless it's the last model of the last iteration)
                    if (responseDelay > 0 && !(iteration === iterationCount - 1 && i === selectedModelIndices.length - 1)) {
                        await new Promise(resolve => setTimeout(resolve, responseDelay));
                    }
                }
            }
        }

        async function handleRotatingMode() {
            // Serial mode with rotating order, repeated for iterationCount times
            for (let iteration = 0; iteration < iterationCount; iteration++) {
                const orderedIndices = [...selectedModelIndices];

                // Rotate based on rotationIndex
                for (let i = 0; i < rotationIndex % orderedIndices.length; i++) {
                    orderedIndices.push(orderedIndices.shift());
                }

                // Process in rotated order
                for (let i = 0; i < orderedIndices.length; i++) {
                    const modelIndex = orderedIndices[i];
                    const model = models[modelIndex];
                    const assistantMessage = {
                        role: 'assistant',
                        content: '',
                        thinking: '',
                        images: [],
                        modelName: model.name,
                        timestamp: Date.now()
                    };
                    currentConversation.push(assistantMessage);
                    renderConversation();
                    await streamResponse(model, assistantMessage);

                    // Save and render after each model completes so next model sees the response
                    saveToStorage();
                    renderConversation();

                    // Add delay before next model (unless it's the last model of the last iteration)
                    if (responseDelay > 0 && !(iteration === iterationCount - 1 && i === orderedIndices.length - 1)) {
                        await new Promise(resolve => setTimeout(resolve, responseDelay));
                    }
                }

                // Increment rotation for next iteration
                rotationIndex++;
                saveToStorage();
            }
        }

        async function handleAutonomousRound() {
            // In autonomous mode, models converse with each other in rotating order
            const orderedIndices = [...selectedModelIndices];

            // Rotate based on rotationIndex
            for (let i = 0; i < rotationIndex % orderedIndices.length; i++) {
                orderedIndices.push(orderedIndices.shift());
            }

            // Pick the next model in rotation
            const modelIndex = orderedIndices[0];
            const model = models[modelIndex];

            const assistantMessage = {
                role: 'assistant',
                content: '',
                thinking: '',
                modelName: model.name,
                timestamp: Date.now()
            };

            currentConversation.push(assistantMessage);
            renderConversation();
            await streamResponse(model, assistantMessage);
            saveToStorage();

            // Increment rotation
            rotationIndex++;
            saveToStorage();
        }

        function resolveApiKey(model) {
            // If model has api_key_id, look up the key
            if (model.api_key_id) {
                const key = apiKeys.find(k => k.id === model.api_key_id);
                if (key) {
                    return key.value;
                }
                throw new Error(`API key not found for ID: ${model.api_key_id}`);
            }
            // Otherwise use the direct api_key
            return model.api_key;
        }

        // Sanitize model names to prevent prompt injection
        function sanitizeModelName(name) {
            if (!name || typeof name !== 'string') {
                return 'Unknown Model';
            }

            // Remove control characters and normalize whitespace
            let sanitized = name
                .replace(/[\r\n\t]+/g, ' ')  // Replace newlines and tabs with spaces
                .replace(/\s+/g, ' ')         // Collapse multiple spaces
                .trim();

            // Limit length to prevent abuse
            if (sanitized.length > 100) {
                sanitized = sanitized.substring(0, 100) + '...';
            }

            // If empty after sanitization, use default
            if (!sanitized) {
                return 'Unknown Model';
            }

            return sanitized;
        }

        function buildSystemPrompt(model) {
            let systemPrompt = '';

            // Add model identity information if enabled and in multi-model mode
            if (enableModelIdentity && selectedModelIndices.length > 1 && model.name) {
                const sanitizedName = sanitizeModelName(model.name);
                systemPrompt = `You are ${sanitizedName}. This is your identity in this conversation. You must always respond as ${sanitizedName}, not as any other participant.\n\n`;

                // Build list of who they're conversing with based on mode
                const conversants = [];

                if (multiModelMode === 'parallel') {
                    // In parallel mode, each model only responds to human independently
                    conversants.push('Human');
                } else if (multiModelMode === 'autonomous') {
                    // In autonomous mode, models only converse with each other (no human)
                    const otherModels = selectedModelIndices
                        .map(idx => models[idx])
                        .filter(m => m.name !== model.name)
                        .map(m => sanitizeModelName(m.name));
                    conversants.push(...otherModels);
                } else {
                    // In serial/rotating modes, models see human AND other models
                    conversants.push('Human');
                    const otherModels = selectedModelIndices
                        .map(idx => models[idx])
                        .filter(m => m.name !== model.name)
                        .map(m => sanitizeModelName(m.name));
                    conversants.push(...otherModels);
                }

                if (conversants.length > 0) {
                    systemPrompt += `You are conversing with: ${conversants.join(', ')}. When you see "X said: ...", that is a message from X. You should respond as ${sanitizedName}, not as any other participant.\n\n`;
                }
            }

            // Use activePromptId if set, otherwise fall back to model's system_prompt
            if (activePromptId) {
                const prompt = systemPrompts.find(p => p.id === activePromptId);
                if (prompt) {
                    systemPrompt += prompt.content;
                }
            } else if (model.system_prompt && model.system_prompt.trim()) {
                systemPrompt += model.system_prompt;
            }

            return systemPrompt.trim();
        }

        async function streamResponse(model, assistantMessage) {
            const messages = buildMessagesForAPI(model, assistantMessage);
            await streamOpenRouter(model, messages, assistantMessage);
        }

        function buildMessagesForAPI(model, excludeMessage = null) {
            const messages = [];
            let lastRole = null;

            // Filter messages based on mode
            let conversationToUse = [...currentConversation];

            // In parallel mode, only include messages from this specific model and user messages
            if (multiModelMode === 'parallel') {
                conversationToUse = conversationToUse.filter(msg =>
                    msg.role === 'user' ||
                    (msg.role === 'assistant' && msg.modelName === model.name)
                );
            }

            // Apply message history limit (0 = all messages)
            if (messageHistoryLimit > 0 && conversationToUse.length > messageHistoryLimit) {
                conversationToUse = conversationToUse.slice(-messageHistoryLimit);
            }

            // Find the most recent user message (to always include its files)
            let mostRecentUserMsg = null;
            for (let i = conversationToUse.length - 1; i >= 0; i--) {
                if (conversationToUse[i].role === 'user' && conversationToUse[i] !== excludeMessage) {
                    mostRecentUserMsg = conversationToUse[i];
                    break;
                }
            }

            for (const msg of conversationToUse) {
                if (msg === excludeMessage) continue; // Skip the message we're currently generating

                if (msg.role === 'user') {
                    let content;

                    // Always include files from the most recent user message, or if includeFilesInHistory is enabled
                    const shouldIncludeFiles = msg.files && msg.files.length > 0 &&
                                               (msg === mostRecentUserMsg || includeFilesInHistory);

                    if (shouldIncludeFiles) {
                        // Has files and should include them - use array format (OpenAI-compatible)
                        content = [];

                        if (msg.content) {
                            content.push({ type: 'text', text: msg.content });
                        }

                        for (const file of msg.files) {
                            if (file.type.startsWith('image/')) {
                                // OpenAI-compatible format (used by OpenRouter)
                                content.push({
                                    type: 'image_url',
                                    image_url: {
                                        url: `data:${file.type};base64,${file.base64}`
                                    }
                                });
                            } else {
                                // For other file types, just mention it
                                content.push({
                                    type: 'text',
                                    text: `[Attached file: ${file.name}]`
                                });
                            }
                        }
                    } else {
                        // No files or should not include files - use simple string format
                        content = msg.content || '';
                    }

                    messages.push({
                        role: 'user',
                        content: content
                    });
                    lastRole = 'user';
                } else if (msg.role === 'assistant') {
                    // Skip messages with empty content (could be streaming failures)
                    if (!msg.content || msg.content.trim() === '') {
                        continue;
                    }

                    // If last message was also assistant, convert it to user to avoid consecutive assistant messages
                    const role = lastRole === 'assistant' ? 'user' : 'assistant';

                    // Add model name prefix if converting to user and model has a name
                    let content = msg.content;
                    if (role === 'user' && msg.modelName) {
                        const sanitizedModelName = sanitizeModelName(msg.modelName);
                        content = `${sanitizedModelName} said: ${msg.content}`;
                    }

                    messages.push({
                        role: role,
                        content: content
                    });
                    lastRole = role; // Track the actual role sent to API, not the original role
                }
            }

            return messages;
        }

        async function streamOpenRouter(model, messages, assistantMessage) {
            // OpenRouter uses OpenAI-compatible API with additional options
            const body = {
                model: model.model_id,
                messages: messages,
                stream: true
            };

            // Add optional parameters if specified
            if (model.max_tokens !== undefined && model.max_tokens !== null) {
                body.max_tokens = model.max_tokens;
            }
            if (model.temperature !== undefined && model.temperature !== null) {
                body.temperature = model.temperature;
            }
            if (model.top_p !== undefined && model.top_p !== null) {
                body.top_p = model.top_p;
            }
            if (model.top_k !== undefined && model.top_k !== null && model.top_k !== 0) {
                body.top_k = model.top_k;
            }
            if (model.frequency_penalty !== undefined && model.frequency_penalty !== null) {
                body.frequency_penalty = model.frequency_penalty;
            }
            if (model.presence_penalty !== undefined && model.presence_penalty !== null) {
                body.presence_penalty = model.presence_penalty;
            }
            if (model.repetition_penalty !== undefined && model.repetition_penalty !== null && model.repetition_penalty !== 1) {
                body.repetition_penalty = model.repetition_penalty;
            }
            if (model.min_p !== undefined && model.min_p !== null && model.min_p !== 0) {
                body.min_p = model.min_p;
            }
            if (model.top_a !== undefined && model.top_a !== null && model.top_a !== 0) {
                body.top_a = model.top_a;
            }
            if (model.seed !== undefined && model.seed !== null) {
                body.seed = model.seed;
            }
            if (model.logit_bias) {
                body.logit_bias = model.logit_bias;
            }
            if (model.logprobs !== undefined && model.logprobs !== null) {
                body.logprobs = model.logprobs;
            }
            if (model.top_logprobs !== undefined && model.top_logprobs !== null) {
                body.top_logprobs = model.top_logprobs;
            }
            if (model.response_format) {
                body.response_format = model.response_format;
            }
            if (model.stop && model.stop.length > 0) {
                body.stop = model.stop;
            }
            if (model.tools) {
                body.tools = model.tools;
            }
            if (model.tool_choice) {
                body.tool_choice = model.tool_choice;
            }
            if (model.reasoning) {
                // Add reasoning parameter (effort: "high" | "medium" | "low" or max_tokens: number)
                body.reasoning = model.reasoning;
            }

            // OpenRouter-specific options
            if (model.transforms) {
                body.transforms = model.transforms;
            }
            if (model.models) {
                body.models = model.models;
            }
            if (model.route) {
                body.route = model.route;
            }
            if (model.provider) {
                body.provider = model.provider;
            }

            // Add system prompt with identity
            const systemPrompt = buildSystemPrompt(model);
            if (systemPrompt) {
                body.messages.unshift({ role: 'system', content: systemPrompt });
            }

            const apiKey = resolveApiKey(model);

            // Validate API key
            if (!apiKey || apiKey.includes('your-')) {
                throw new Error('Invalid or missing API key. Please add a valid OpenRouter API key in Settings.');
            }

            // Build headers
            const headers = {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`,
                'HTTP-Referer': window.location.href,
                'X-Title': 'OpenRouter Multi-Model Chat'
            };

            // Add custom headers (OpenRouter recommends HTTP-Referer and X-Title)
            if (model.headers) {
                Object.assign(headers, model.headers);
            }

            let response;
            const controller = new AbortController();
            currentAbortControllers.push(controller);

            try {
                // Add timeout to prevent hanging
                const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout

                response = await fetch(model.endpoint, {
                    method: 'POST',
                    headers: headers,
                    body: JSON.stringify(body),
                    signal: controller.signal
                });

                clearTimeout(timeoutId);
            } catch (e) {
                console.error('Fetch error:', e);
                if (e.name === 'AbortError') {
                    throw new Error('Request stopped.');
                }
                throw new Error(`Network error: ${e.message}. Check your internet connection and make sure the endpoint is correct.`);
            }

            if (!response.ok) {
                let errorText;
                try {
                    errorText = await response.text();
                    console.error('API error response:', errorText);

                    // Try to parse as JSON for better error message
                    try {
                        const errorJson = JSON.parse(errorText);
                        if (errorJson.error && errorJson.error.message) {
                            errorText = errorJson.error.message;
                        }
                    } catch (e) {
                        // Not JSON, use as-is
                    }
                } catch (e) {
                    errorText = 'Could not read error response';
                }

                if (response.status === 401) {
                    throw new Error(`Authentication failed. Your API key may be invalid or expired. Status: ${response.status}`);
                } else if (response.status === 402) {
                    throw new Error(`Insufficient credits. Please add credits to your OpenRouter account. Status: ${response.status}`);
                } else if (response.status === 429) {
                    throw new Error(`Rate limit exceeded. Please wait a moment and try again. Status: ${response.status}`);
                } else {
                    throw new Error(`API error ${response.status}: ${errorText}`);
                }
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            let finishReason = null;
            let hasReceivedContent = false;

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                buffer += decoder.decode(value, { stream: true });
                const lines = buffer.split('\n');
                buffer = lines.pop();

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;

                        try {
                            const parsed = JSON.parse(data);
                            const delta = parsed.choices?.[0]?.delta;

                            // Handle content (can be string or array of content blocks)
                            if (delta?.content) {
                                // Check if content is an array (multi-part content with text and images)
                                if (Array.isArray(delta.content)) {
                                    for (const block of delta.content) {
                                        if (block.type === 'text' && block.text) {
                                            assistantMessage.content += block.text;
                                            hasReceivedContent = true;
                                        } else if (block.type === 'image_url' && block.image_url?.url) {
                                            if (!assistantMessage.images) {
                                                assistantMessage.images = [];
                                            }
                                            // Add image if not already present
                                            if (!assistantMessage.images.find(i => i.url === block.image_url.url)) {
                                                assistantMessage.images.push({
                                                    url: block.image_url.url
                                                });
                                            }
                                        }
                                    }
                                    renderConversation();
                                } else if (typeof delta.content === 'string') {
                                    // String content (most common case)
                                    assistantMessage.content += delta.content;
                                    hasReceivedContent = true;
                                    renderConversation();
                                }
                            }

                            // Track finish reason
                            if (parsed.choices?.[0]?.finish_reason) {
                                finishReason = parsed.choices[0].finish_reason;
                            }

                            // Handle reasoning/thinking content when streaming
                            if (delta?.reasoning) {
                                assistantMessage.thinking += delta.reasoning;
                                renderConversation();
                            }

                            // Check for images in the response (for non-streaming or final chunk)
                            const message = parsed.choices?.[0]?.message;
                            if (message?.images && message.images.length > 0) {
                                if (!assistantMessage.images) {
                                    assistantMessage.images = [];
                                }
                                // Add any new images that aren't already present
                                for (const img of message.images) {
                                    if (img.image_url?.url && !assistantMessage.images.find(i => i.url === img.image_url.url)) {
                                        assistantMessage.images.push({
                                            url: img.image_url.url
                                        });
                                    }
                                }
                                renderConversation();
                            }

                            // Also check for content array in message (non-streaming response)
                            if (message?.content && Array.isArray(message.content)) {
                                for (const block of message.content) {
                                    if (block.type === 'text' && block.text) {
                                        assistantMessage.content += block.text;
                                    } else if (block.type === 'image_url' && block.image_url?.url) {
                                        if (!assistantMessage.images) {
                                            assistantMessage.images = [];
                                        }
                                        if (!assistantMessage.images.find(i => i.url === block.image_url.url)) {
                                            assistantMessage.images.push({
                                                url: block.image_url.url
                                            });
                                        }
                                    }
                                }
                                renderConversation();
                            }
                        } catch (e) {
                            console.error('Error parsing SSE:', e, 'Line:', line);
                        }
                    }
                }
            }

            // Validate that we received content
            if (!hasReceivedContent && !assistantMessage.content && !assistantMessage.thinking) {
                // Log diagnostic information
                console.warn('Model completed streaming with no content', {
                    model: model.name,
                    finishReason: finishReason,
                    hasImages: assistantMessage.images?.length > 0
                });

                // Throw error with helpful message based on finish reason
                if (finishReason === 'content_filter') {
                    throw new Error(`${model.name} declined to respond due to content filter. Try rephrasing your message.`);
                } else if (finishReason === 'length') {
                    throw new Error(`${model.name} hit token limit before responding. Try reducing message history or increasing max_tokens.`);
                } else if (finishReason) {
                    throw new Error(`${model.name} stopped with reason: ${finishReason} (no content generated)`);
                } else {
                    throw new Error(`${model.name} completed streaming but provided no response. This may be a model issue or API error.`);
                }
            }
        }

        function renderConversation() {
            const container = document.getElementById('chat-messages');
            container.innerHTML = '';

            currentConversation.forEach((msg, index) => {
                if (msg.role === 'user') {
                    const div = document.createElement('div');
                    div.className = 'message user';
                    
                    let contentHtml = `<div class="message-content">${escapeHtml(msg.content)}</div>`;
                    
                    if (msg.files) {
                        for (const file of msg.files) {
                            if (file.type.startsWith('image/')) {
                                contentHtml += `<div class="file-preview"><img src="data:${file.type};base64,${file.base64}" alt="${escapeHtml(file.name)}"></div>`;
                            } else if (file.type.startsWith('video/')) {
                                contentHtml += `<div class="file-preview"><video controls src="data:${file.type};base64,${file.base64}"></video></div>`;
                            } else {
                                contentHtml += `<div class="file-info">${escapeHtml(file.name)} (${formatFileSize(file.size)})</div>`;
                            }
                        }
                    }

                    contentHtml += `<div class="message-actions">
                        <button onclick="editMessage(${index})">Edit & Resend</button>
                    </div>`;
                    
                    div.innerHTML = contentHtml;
                    container.appendChild(div);
                } else if (msg.role === 'assistant') {
                    const div = document.createElement('div');
                    div.className = 'message assistant';
                    const rendered = renderMarkdownWithLatex(msg.content);
                    let contentHtml = '';

                    // Show model name if multiple models are selected
                    if (msg.modelName && selectedModelIndices.length > 1) {
                        contentHtml += `<div style="font-size: 12px; color: #888; margin-bottom: 8px; font-weight: 600;">${escapeHtml(msg.modelName)}</div>`;
                    }

                    // Show inline thinking indicator if currently streaming thinking
                    const isStreamingThisMessage = isStreaming && currentConversation[currentConversation.length - 1] === msg;
                    if (isStreamingThisMessage && msg.thinking && !msg.content) {
                        contentHtml += `
                            <div class="inline-thinking-indicator">
                                <span>Thinking...</span>
                                <div class="dot"></div>
                                <div class="dot"></div>
                                <div class="dot"></div>
                            </div>
                        `;
                    }

                    // Show thinking content if it exists (collapsible)
                    if (msg.thinking) {
                        const thinkingId = `thinking-${index}`;
                        contentHtml += `
                            <div class="thinking-toggle" onclick="toggleThinking('${thinkingId}')">
                                Chain of Thought (click to ${msg.thinkingCollapsed !== false ? 'expand' : 'collapse'})
                            </div>
                            <div id="${thinkingId}" class="thinking-content${msg.thinkingCollapsed !== false ? ' collapsed' : ''}">
                                ${escapeHtml(msg.thinking)}
                            </div>
                        `;
                    }

                    contentHtml += `<div class="message-content">${rendered}</div>`;

                    // Render received images
                    if (msg.images && msg.images.length > 0) {
                        for (const image of msg.images) {
                            contentHtml += `<div class="file-preview"><img src="${escapeHtml(image.url)}" alt="Generated image" style="max-width: 100%; height: auto; border-radius: 6px; margin-top: 12px;"></div>`;
                        }
                    }

                    // Add edit and regenerate buttons
                    contentHtml += `
                        <div style="margin-top: 8px; display: flex; gap: 8px;">
                            <button onclick="editAssistantMessage(${index})" style="font-size: 11px; padding: 4px 8px; background: #4a4a4a; border: none; color: #e0e0e0; border-radius: 4px; cursor: pointer;">Edit</button>
                            <button onclick="regenerateResponse(${index})" style="font-size: 11px; padding: 4px 8px; background: #4a4a4a; border: none; color: #e0e0e0; border-radius: 4px; cursor: pointer;">Regenerate</button>
                        </div>
                    `;

                    div.innerHTML = contentHtml;
                    container.appendChild(div);
                }
            });

            container.scrollTop = container.scrollHeight;
        }

        function toggleThinking(thinkingId) {
            const element = document.getElementById(thinkingId);
            if (element) {
                element.classList.toggle('collapsed');

                // Update the message's collapsed state
                const index = parseInt(thinkingId.split('-')[1]);
                if (currentConversation[index]) {
                    currentConversation[index].thinkingCollapsed = element.classList.contains('collapsed');
                    saveToStorage();
                }
            }
        }

        function editMessage(index) {
            const msg = currentConversation[index];
            document.getElementById('message-input').value = msg.content;
            editingMessageIndex = index;

            // Load files if any
            if (msg.files) {
                attachedFiles = [...msg.files];
                renderAttachedFiles();
            }
        }

        function editAssistantMessage(index) {
            const msg = currentConversation[index];
            if (msg.role !== 'assistant') return;

            const newContent = prompt('Edit AI response:', msg.content);
            if (newContent === null) return; // User cancelled

            // Update the message content
            msg.content = newContent;

            // Truncate conversation after this message
            currentConversation = currentConversation.slice(0, index + 1);

            saveToStorage();
            renderConversation();
        }

        async function regenerateResponse(index) {
            const msg = currentConversation[index];
            if (msg.role !== 'assistant') return;
            if (isStreaming) return;

            // Find which model generated this response
            let model = null;

            if (msg.modelName) {
                // Find the model by name
                model = models.find(m => m.name === msg.modelName);
                if (!model) {
                    alert(`Cannot regenerate: model "${msg.modelName}" not found in your saved models`);
                    return;
                }
            } else if (selectedModelIndices.length === 1) {
                // If only one model selected, use that
                model = models[selectedModelIndices[0]];
            } else if (selectedModelIndices.length > 1) {
                // Multiple models but no modelName - ask user to select
                alert('Cannot regenerate: Multiple models selected but original model not identified. This may be an old message.');
                return;
            } else {
                alert('Cannot regenerate: No models selected');
                return;
            }

            // Truncate conversation to just before this message
            currentConversation = currentConversation.slice(0, index);

            // Create new assistant message for regeneration
            const assistantMessage = {
                role: 'assistant',
                content: '',
                thinking: '',
                modelName: model.name,
                timestamp: Date.now()
            };

            currentConversation.push(assistantMessage);
            renderConversation();
            saveToStorage();

            // Regenerate the response
            isStreaming = true;
            currentAbortControllers = [];
            showStopButton();
            startBackgroundAudio(); // Keep iOS active during generation

            try {
                await streamResponse(model, assistantMessage);
            } catch (error) {
                console.error('Regeneration error:', error);
                assistantMessage.content = 'Error: ' + error.message;
                renderConversation();
            }

            isStreaming = false;
            stopBackgroundAudio(); // Stop silent audio when done
            currentAbortControllers = [];
            hideStopButton();
            saveToStorage();
            renderConversation();
        }

        function renderMarkdownWithLatex(text) {
            if (!text) return '';

            // Escape HTML first
            let escaped = escapeHtml(text);

            // Render block LaTeX first - process all block formats before inline
            // Format: \[ ... \] (standard LaTeX display math)
            escaped = escaped.replace(/\\\[([\s\S]+?)\\\]/g, (match, latex) => {
                try {
                    return katex.renderToString(latex.trim(), { throwOnError: false, displayMode: true });
                } catch (e) {
                    return match;
                }
            });

            // Format: $$ ... $$ (alternative display math)
            escaped = escaped.replace(/\$\$([\s\S]+?)\$\$/g, (match, latex) => {
                try {
                    return katex.renderToString(latex.trim(), { throwOnError: false, displayMode: true });
                } catch (e) {
                    return match;
                }
            });

            // Render inline LaTeX - process all inline formats
            // Format: \( ... \) (standard LaTeX inline math)
            escaped = escaped.replace(/\\\(([\s\S]+?)\\\)/g, (match, latex) => {
                try {
                    return katex.renderToString(latex.trim(), { throwOnError: false, displayMode: false });
                } catch (e) {
                    return match;
                }
            });

            // Format: $ ... $ (alternative inline math)
            escaped = escaped.replace(/\$([^\$\n]+)\$/g, (match, latex) => {
                try {
                    return katex.renderToString(latex, { throwOnError: false, displayMode: false });
                } catch (e) {
                    return match;
                }
            });

            // Code blocks - must come before inline code
            escaped = escaped.replace(/```([\s\S]+?)```/g, '<pre style="background: #2a2a2a; padding: 12px; border-radius: 6px; overflow-x: auto; margin: 8px 0;">$1</pre>');

            // Simple markdown: **bold**, *italic*, `code`
            // Use [\s\S] to match across newlines
            escaped = escaped.replace(/\*\*([\s\S]+?)\*\*/g, '<strong>$1</strong>');
            escaped = escaped.replace(/\*([\s\S]+?)\*/g, '<em>$1</em>');
            escaped = escaped.replace(/`([^`\n]+)`/g, '<code style="background: #3a3a3a; padding: 2px 6px; border-radius: 3px;">$1</code>');

            return escaped;
        }

        function renderHistory() {
            const list = document.getElementById('history-list');
            let html = '';

            // Show current conversation
            if (currentConversation.length > 0) {
                const summary = currentConversation.slice(0, 2).map(msg => {
                    if (msg.role === 'user') return 'User: ' + msg.content.substring(0, 50);
                    return 'Assistant: ' + msg.content.substring(0, 50);
                }).join('\n');

                html += `
                    <div class="history-item">
                        <h4>Current Conversation</h4>
                        <div style="white-space: pre-wrap; font-size: 13px; color: #aaa;">${escapeHtml(summary)}...</div>
                        <div style="color: #666; font-size: 12px; margin-top: 8px;">${currentConversation.length} messages</div>
                        <div class="history-actions">
                            <button onclick="exportConversation()">Export</button>
                            <button onclick="clearConversation()">Clear</button>
                        </div>
                    </div>
                `;
            }

            // Show saved conversation history
            if (conversationHistory.length > 0) {
                html += '<h3 style="margin-top: 20px; margin-bottom: 12px; color: #4a9eff;">Saved Conversations</h3>';

                conversationHistory.forEach((entry, index) => {
                    const date = new Date(entry.timestamp);
                    const dateStr = date.toLocaleDateString() + ' ' + date.toLocaleTimeString();
                    const summary = entry.conversation.slice(0, 2).map(msg => {
                        if (msg.role === 'user') return 'User: ' + (msg.content || '').substring(0, 50);
                        return 'Assistant: ' + (msg.content || '').substring(0, 50);
                    }).join('\n');

                    html += `
                        <div class="history-item">
                            <h4>${escapeHtml(dateStr)}</h4>
                            <div style="white-space: pre-wrap; font-size: 13px; color: #aaa;">${escapeHtml(summary)}...</div>
                            <div style="color: #666; font-size: 12px; margin-top: 8px;">${entry.messageCount} messages</div>
                            <div class="history-actions">
                                <button onclick="loadConversation(${index})">Load</button>
                                <button onclick="exportHistoryItem(${index})">Export</button>
                                <button onclick="deleteHistoryItem(${index})">Delete</button>
                            </div>
                        </div>
                    `;
                });
            }

            if (!html) {
                html = '<p style="color: #888;">No conversation history yet. Start a chat and click "New Chat" to save it.</p>';
            }

            list.innerHTML = html;
        }

        function loadConversation(index) {
            if (!confirm('Load this conversation? Current conversation will be replaced.')) return;

            const entry = conversationHistory[index];
            if (entry) {
                currentConversation = [...entry.conversation];
                saveToStorage();
                renderConversation();
                renderHistory();
                switchTab('chat');
            }
        }

        function exportHistoryItem(index) {
            const entry = conversationHistory[index];
            if (entry) {
                const data = {
                    conversation: entry.conversation,
                    timestamp: entry.timestamp
                };
                downloadJSON(data, `conversation-${entry.id}.json`);
            }
        }

        function deleteHistoryItem(index) {
            if (!confirm('Delete this conversation from history?')) return;

            conversationHistory.splice(index, 1);
            saveToStorage();
            renderHistory();
        }

        function newChat() {
            if (currentConversation.length > 0) {
                // Automatically save current conversation to history
                const historyEntry = {
                    id: Date.now().toString(),
                    timestamp: new Date().toISOString(),
                    conversation: [...currentConversation],
                    messageCount: currentConversation.length
                };
                conversationHistory.unshift(historyEntry); // Add to beginning of array

                // Keep only last 50 conversations to avoid excessive storage
                if (conversationHistory.length > 50) {
                    conversationHistory = conversationHistory.slice(0, 50);
                }
            }

            currentConversation = [];
            attachedFiles = [];
            editingMessageIndex = null;
            saveToStorage();
            renderConversation();
            renderHistory();
            renderAttachedFiles();
            document.getElementById('message-input').value = '';
        }

        function clearConversation() {
            if (!confirm('Clear current conversation?')) return;
            currentConversation = [];
            saveToStorage();
            renderConversation();
            renderHistory();
        }

        function clearHistory() {
            clearConversation();
        }

        function exportConversation() {
            const data = {
                conversation: currentConversation,
                timestamp: new Date().toISOString()
            };
            downloadJSON(data, `conversation-${Date.now()}.json`);
        }

        function importHistory(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = (e) => {
                try {
                    const data = JSON.parse(e.target.result);

                    if (data.conversation && Array.isArray(data.conversation)) {
                        // Replace current conversation with imported one
                        currentConversation = data.conversation;
                        saveToStorage();
                        renderConversation();
                        renderHistory();
                        alert('History imported successfully!');
                        // Switch to chat tab to see the imported conversation
                        switchTab('chat');
                    } else {
                        alert('Invalid history file format. Expected a conversation array.');
                    }
                } catch (e) {
                    alert('Error importing history: ' + e.message);
                }
            };
            reader.readAsText(file);
            event.target.value = '';
        }

        function exportData() {
            const data = {
                models,
                apiKeys,
                systemPrompts,
                activePromptId,
                currentConversation,
                exportDate: new Date().toISOString()
            };
            downloadJSON(data, `api-chat-backup-${Date.now()}.json`);
        }

        function importData(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = async (e) => {
                try {
                    const data = JSON.parse(e.target.result);

                    if (data.models) models = data.models;
                    if (data.apiKeys) apiKeys = data.apiKeys;
                    if (data.systemPrompts) systemPrompts = data.systemPrompts;
                    if (data.activePromptId) activePromptId = data.activePromptId;
                    if (data.currentConversation) currentConversation = data.currentConversation;

                    await saveToStorage();
                    await init();
                    alert('Data imported successfully!');
                } catch (e) {
                    alert('Error importing data: ' + e.message);
                }
            };
            reader.readAsText(file);
            event.target.value = '';
        }

        function downloadJSON(data, filename) {
            const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            a.click();
            URL.revokeObjectURL(url);
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // Initialize on load
        init();
    </script>
</body>
</html>
